# Extract Processing Service - Developer Guide

## Overview
This document provides implementation details for the Extract Processing Service, a Spring Boot WebAPI that manages and executes daily and weekly extract jobs. The service is designed to be flexible, configurable, and can be triggered both manually via REST endpoints and automatically through Control-M scheduling.

## System Architecture

### Components
1. **REST API Layer**: Handles incoming HTTP requests to trigger extract jobs
2. **Service Layer**: Contains business logic for processing different types of extracts
3. **Configuration Layer**: Manages extract configurations through application properties
4. **Execution Layer**: Handles the actual running of extract jobs

### Technology Stack
- Spring Boot 3.x
- Java 17+
- Maven/Gradle
- Spring Scheduler (for local testing)

## Configuration

### Application Properties
```properties
# Extract Configurations
extracts.daily.order=E5,E3,E8,E7,E8
extracts.weekly.order=S1,E1,E2,E4,EA,E9
extracts.monthly.order=E6

# Extract Job Paths/Commands
extracts.base.path=/path/to/extract/scripts
extracts.E5.command=./run_extract_E5.sh
extracts.E3.command=./run_extract_E3.sh
# ... Add other extract commands

# Logging Configuration
logging.level.com.company.extractservice=INFO
logging.file.name=extract-service.log
```

## API Endpoints

### 1. Trigger Extract Job
```
POST /api/v1/extracts/run
```

Request Body:
```json
{
    "type": "DAILY",  // or "WEEKLY"
    "requestId": "unique-request-id",
    "force": false    // override if already running
}
```

Response:
```json
{
    "status": "ACCEPTED",
    "jobId": "job-123",
    "message": "Extract job started successfully"
}
```

### 2. Check Job Status
```
GET /api/v1/extracts/status/{jobId}
```

## OpenShift-Specific Implementation Details

When running in OpenShift, the service needs to be adapted to handle YAML configurations:

```java
@Configuration
@ConfigurationProperties(prefix = "extracts")
public class ExtractConfig {
    private Map<String, String> daily;
    private Map<String, String> weekly;
    private ControlMConfig controlM;
    
    // Getters and setters
}

@Configuration
@ConfigurationProperties(prefix = "control-m")
public class ControlMConfig {
    private boolean enabled;
    private String endpoint;
    private AuthConfig auth;
    
    // Getters and setters
}
```

### OpenShift Environment Detection
```java
@Component
public class EnvironmentDetector {
    private final boolean isOpenShift;
    
    public EnvironmentDetector() {
        this.isOpenShift = System.getenv("OPENSHIFT_BUILD_NAME") != null;
    }
    
    public boolean isOpenShiftEnvironment() {
        return isOpenShift;
    }
}
```

## Standard Implementation Details

### Core Classes

#### 1. Extract Controller
```java
@RestController
@RequestMapping("/api/v1/extracts")
public class ExtractController {
    @PostMapping("/run")
    public ResponseEntity<JobResponse> runExtract(@RequestBody ExtractRequest request) {
        // Implementation
    }
    
    @GetMapping("/status/{jobId}")
    public ResponseEntity<JobStatus> getStatus(@PathVariable String jobId) {
        // Implementation
    }
}
```

#### 2. Extract Service
```java
@Service
@Slf4j
public class ExtractService {
    @Value("${extracts.daily.order}")
    private String dailyOrder;
    
    @Value("${extracts.weekly.order}")
    private String weeklyOrder;
    
    public JobResponse processExtract(ExtractRequest request) {
        String[] extractOrder = getExtractOrder(request.getType());
        // Implementation
    }
    
    private String[] getExtractOrder(ExtractType type) {
        return switch(type) {
            case DAILY -> dailyOrder.split(",");
            case WEEKLY -> weeklyOrder.split(",");
            default -> throw new IllegalArgumentException("Invalid extract type");
        };
    }
}
```

## OpenShift Deployment

### OpenShift Configuration
When deploying to OpenShift with Control-M integration, the service requires specific YAML configurations:

1. **Deployment YAML**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: extract-service
  namespace: extract-processing
spec:
  replicas: 1
  selector:
    matchLabels:
      app: extract-service
  template:
    metadata:
      labels:
        app: extract-service
    spec:
      containers:
      - name: extract-service
        image: ${REGISTRY}/extract-service:${TAG}
        ports:
        - containerPort: 8080
        envFrom:
        - configMapRef:
            name: extract-service-config
        volumeMounts:
        - name: extract-config
          mountPath: /app/config
        - name: extract-scripts
          mountPath: /app/scripts
      volumes:
      - name: extract-config
        configMap:
          name: extract-service-config
      - name: extract-scripts
        persistentVolumeClaim:
          claimName: extract-scripts-pvc
```

2. **ConfigMap YAML**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: extract-service-config
  namespace: extract-processing
data:
  application.yaml: |
    extracts:
      daily:
        order: E5,E3,E8,E7,E8
      weekly:
        order: S1,E1,E2,E4,EA,E9
      monthly:
        order: E6
    
    control-m:
      enabled: true
      endpoint: https://controlm-api:8443/automation-api
      auth:
        username: ${CONTROLM_USER}
        password: ${CONTROLM_PASSWORD}
    
    logging:
      level:
        com.company.extractservice: INFO
      file:
        name: /var/log/extract-service.log
```

3. **Service YAML**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: extract-service
  namespace: extract-processing
spec:
  selector:
    app: extract-service
  ports:
  - port: 8080
    targetPort: 8080
  type: ClusterIP
```

4. **Route YAML (for OpenShift)**
```yaml
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: extract-service
  namespace: extract-processing
spec:
  to:
    kind: Service
    name: extract-service
  tls:
    termination: edge
```

### Control-M Integration in OpenShift

When running in OpenShift, Control-M jobs need to be configured to use the OpenShift route:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: control-m-jobs
  namespace: extract-processing
data:
  daily-extract.json: |
    {
      "jobName": "EXTRACT_SERVICE_DAILY",
      "command": "curl -X POST https://extract-service-route.apps.openshift.com/api/v1/extracts/run -H \"Content-Type: application/json\" -H \"X-API-Key: ${API_KEY}\" -d '{\"type\":\"DAILY\",\"requestId\":\"%%JOBID%%\"}'",
      "schedule": "EVERYDAY",
      "time": "01:00",
      "runAs": "extract-service",
      "application": "ExtractProcessing",
      "subApplication": "DailyExtracts"
    }
```

### OpenShift-Specific Considerations

1. **Resource Limits**
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "500m"
```

2. **Health Checks**
```yaml
livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: 8080
  initialDelaySeconds: 60
  periodSeconds: 10
readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
```

3. **Security Context**
```yaml
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
```

## Standard Deployment

### Local Development
1. Clone the repository
2. Configure application.properties
3. Run using Maven:
```bash
mvn spring-boot:run
```

### Production Deployment
1. Build the JAR:
```bash
mvn clean package
```

2. Deploy to server:
```bash
java -jar extract-service.jar --spring.config.location=file:/path/to/application.properties
```

### Control-M Integration

#### Job Configuration
```bash
# Control-M Job Definition
JOBNAME: EXTRACT_SERVICE_DAILY
COMMAND: curl -X POST http://extract-service:8080/api/v1/extracts/run -H "Content-Type: application/json" -d '{"type":"DAILY","requestId":"%%JOBID%%"}'
SCHEDULE: EVERYDAY
TIME: 01:00
```

## Error Handling

The service implements the following error handling:
1. **Concurrent Execution Protection**: Prevents multiple instances of the same extract type running simultaneously
2. **Job Monitoring**: Tracks job status and provides detailed error information
3. **Retry Mechanism**: Configurable retry policy for failed extracts

## Monitoring

### Metrics
The service exposes the following metrics through Spring Actuator:
- extract_job_duration_seconds
- extract_job_success_total
- extract_job_failure_total

### Logging
Implements structured logging with the following information:
- Request ID
- Extract Type
- Start/End Time
- Status
- Error Details (if any)

## Security

### API Security
1. Implement API key authentication:
```java
@Configuration
public class SecurityConfig {
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) {
        http.csrf().disable()
            .authorizeRequests()
            .requestMatchers("/api/v1/extracts/**").hasRole("EXTRACT_ADMIN")
            .anyRequest().authenticated()
            .and()
            .addFilter(new ApiKeyAuthFilter());
        return http.build();
    }
}
```

2. Configure CORS and rate limiting as needed

## Testing

### Unit Tests
```java
@SpringBootTest
class ExtractServiceTest {
    @Test
    void whenDailyExtractRequested_thenCorrectOrderIsProcessed() {
        // Test implementation
    }
}
```

### Integration Tests
Provide Postman collection for API testing:
```json
{
    "name": "Extract Service Tests",
    "requests": [
        {
            "name": "Run Daily Extract",
            "method": "POST",
            "url": "{{base_url}}/api/v1/extracts/run",
            "body": {
                "type": "DAILY",
                "requestId": "test-123"
            }
        }
    ]
}
```

## Troubleshooting

Common issues and solutions:
1. **Job Hanging**: Implement timeout mechanism
2. **Extract Order Mismatch**: Validate configuration at startup
3. **Control-M Integration Issues**: Proper error handling and logging

## Best Practices

1. Always use request IDs for tracking
2. Implement circuit breakers for external dependencies
3. Use appropriate timeout values
4. Maintain comprehensive logging
5. Regular monitoring of job execution times
6. Implement proper cleanup of temporary files
7. Regular backup of configuration

## Contact

For questions or issues:
- Team: Extract Processing Team
- Email: extract-team@company.com
- Slack: #extract-service-support
